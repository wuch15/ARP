{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import random\n",
    "import numpy as np\n",
    "with open('rating_data.txt')as f:\n",
    "    data=f.readlines()\n",
    "\n",
    "sent=[]\n",
    "for x in data:\n",
    "    if len(x.split('\\t'))==7:\n",
    "        sent.append(list(jieba.cut(x.replace('<sssss>','').replace('\\n','').split('\\t')[6])))\n",
    "\n",
    "sentchar=[x.replace('<sssss>','').replace('\\n','').split('\\t')[6] for x in data if len(x.split('\\t'))==7]\n",
    "label=np.asarray([x.replace('<sssss>','').split('\\t')[:6] for x in data if len(x.split('\\t'))==7]ï¼‰\n",
    "\n",
    "\n",
    "word_dict={'padding':[0,999999]}\n",
    "for i in sent:\n",
    "    for j in i:\n",
    "        if j not in word_dict:\n",
    "            word_dict[j]=[len(word_dict),1]\n",
    "        else:\n",
    "            word_dict[j][1]+=1\n",
    "\n",
    "char_dict={'padding':0}\n",
    "for i in sentchar:\n",
    "    for j in i:\n",
    "        if j not in char_dict:\n",
    "            char_dict[j]=len(char_dict)\n",
    "\n",
    "\n",
    "MAX_SENT_LENGTH=750\n",
    "MAX_SENT_LENGTH_CHAR=1500\n",
    "                 \n",
    "idsent=[]\n",
    "for i in sent:\n",
    "    tokens=[word_dict[j][0] for j in i if word_dict[j][0]>=10]\n",
    "    tokens=tokens[:MAX_SENT_LENGTH]\n",
    "    tokens+=[0]*(MAX_SENT_LENGTH-len(tokens))\n",
    "    idsent.append(tokens)\n",
    "\n",
    "idsentchar=[]\n",
    "for i in sentchar:\n",
    "    tokens=[char_dict[j] for j in i]\n",
    "    tokens=tokens[:MAX_SENT_LENGTH_CHAR]\n",
    "    tokens+=[0]*(MAX_SENT_LENGTH_CHAR-len(tokens))\n",
    "    idsentchar.append(tokens)\n",
    "\n",
    "all_data=np.array(idsent,dtype='int32')\n",
    "all_data_char=np.array(idsentchar,dtype='int32')\n",
    "\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers #keras2\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "\n",
    "class AttLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs): \n",
    "        self.init = initializers.get('normal') \n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], 1)))\n",
    "        self.b = K.variable(self.init(( 1,))) \n",
    "        self.trainable_weights = [self.W,self.b]\n",
    "        super(AttLayer, self).build(input_shape)   \n",
    "\n",
    "    def call(self, x, mask=None):\n",
    " \n",
    "        eij = K.tanh(K.dot(x, self.W)+self.b)\n",
    "        ai = K.exp(eij)\n",
    " \n",
    "        weights = ai / K.expand_dims(K.sum(ai, axis=1), 1)\n",
    "        print('weights', weights.shape)\n",
    "        weighted_input = x * weights \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "                 \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "index=list(range(len(label)))\n",
    "random.shuffle(index)\n",
    "\n",
    "train_reviews=all_data[index[:int(len(label)*0.8)]]\n",
    "val_reviews=all_data[index[int(len(label)*0.8):int(len(label)*0.9)]]\n",
    "test_reviews=all_data[index[int(len(label)*0.9):]]\n",
    "                 \n",
    "train_reviews_char=all_data_char[index[:int(len(label)*0.8)]]\n",
    "val_reviews_char=all_data_char[index[int(len(label)*0.8):int(len(label)*0.9)]]\n",
    "test_reviews_char=all_data_char[index[int(len(label)*0.9):]]\n",
    "                 \n",
    "train_label=label[index[:int(len(label)*0.8)]]\n",
    "val_label=label[index[int(len(label)*0.8):int(len(label)*0.9)]]\n",
    "test_label=label[index[int(len(label)*0.9):]]\n",
    "\n",
    "for repeat in range(10):\n",
    "    keras.backend.clear_session()\n",
    "    embedding_layer = Embedding(len(word_dict),200,input_length=MAX_SENT_LENGTH, trainable=True)\n",
    "    embedding_layer_char = Embedding(len(char_dict),100,input_length=MAX_SENT_LENGTH_CHAR, trainable=True)\n",
    "    \n",
    "    review_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "    review_embedded_sequences = embedding_layer(review_input)\n",
    "    d_review_emb=Dropout(0.2)(review_embedded_sequences)\n",
    "    \n",
    "    review_input_char = Input(shape=(MAX_SENT_LENGTH_CHAR,), dtype='int32')\n",
    "    review_embedded_sequences_char = embedding_layer_char(review_input_char)\n",
    "    d_review_emb_char=Dropout(0.2)(review_embedded_sequences_char)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    review_w_cnn = Convolution1D(nb_filter=200, filter_length=3, padding='same', activation='relu', strides=1)(d_review_emb)\n",
    "    review_d_w_cnn = Dropout(0.2)(review_w_cnn)\n",
    "    \n",
    "    \n",
    "    review_c_cnn = Convolution1D(nb_filter=100, filter_length=3, padding='same', activation='relu', strides=1)(d_review_emb_char)\n",
    "    review_d_c_cnn = Dropout(0.2)(review_c_cnn)\n",
    "    \n",
    "    \n",
    "    review_w_att1 = AttLayer()(review_d_w_cnn)\n",
    "    review_c_att1 = AttLayer()(review_d_c_cnn)\n",
    "    review_att1=concatenate([review_w_att1,review_c_att1])\n",
    "    \n",
    "    \n",
    "    review_w_att2 = AttLayer()(review_d_w_cnn)\n",
    "    review_c_att2 = AttLayer()(review_d_c_cnn)\n",
    "    review_att2=concatenate([review_w_att2,review_c_att2])\n",
    "    aspect_score1=Dense(1)(review_att2)\n",
    "    \n",
    "    review_w_att3 = AttLayer()(review_d_w_cnn)\n",
    "    review_c_att3 = AttLayer()(review_d_c_cnn)\n",
    "    review_att3=concatenate([review_w_att3,review_c_att3])\n",
    "    aspect_score2=Dense(1)(review_att3)\n",
    "    \n",
    "    review_w_att4 = AttLayer()(review_d_w_cnn)\n",
    "    review_c_att4 = AttLayer()(review_d_c_cnn)\n",
    "    review_att4=concatenate([review_w_att4,review_c_att4])\n",
    "    aspect_score3=Dense(1)(review_att4)\n",
    "    \n",
    "    review_w_att5 = AttLayer()(review_d_w_cnn)\n",
    "    review_c_att5 = AttLayer()(review_d_c_cnn)\n",
    "    review_att5=concatenate([review_w_att5,review_c_att5])\n",
    "    aspect_score4=Dense(1)(review_att5)\n",
    "    \n",
    "    review_w_att6 = AttLayer()(review_d_w_cnn)\n",
    "    review_c_att6 = AttLayer()(review_d_c_cnn)\n",
    "    review_att6=concatenate([review_w_att6,review_c_att6])\n",
    "    aspect_score5=Dense(1)(review_att6)\n",
    "    \n",
    "    \n",
    "    overall_rep = concatenate([review_att1,review_att2,review_att3,review_att4,review_att5,review_att6])\n",
    "    overall_score=Dense(1)(overall_rep)\n",
    "    \n",
    "    aspect_score = concatenate([aspect_score1,aspect_score2,aspect_score3,aspect_score4,aspect_score5])\n",
    "\n",
    "\n",
    "\n",
    "    model = Model([review_input,review_input_char], [overall_score,aspect_score])\n",
    "    \n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['acc'],loss_weights=[0.5,0.5])\n",
    "    \n",
    "    for p in range(10):\n",
    "        model.fit([train_reviews,train_reviews_char],[train_label[:,:1],train_label[:,1:]],shuffle=True, batch_size=50, epochs=1,verbose=1)\n",
    "        \n",
    "        y_pred = model.predict([val_reviews,val_reviews_char], batch_size=50, verbose=1)[0]\n",
    "        result=np.mean(np.abs(y_pred-val_label),axis=0)\n",
    "        overall=np.round(np.minimum(np.maximum(y_pred,1),5))\n",
    "        print(result,accuracy_score(overall,val_label[:,:1]))#MAE,Acc\n",
    "        \n",
    "        y_pred = model.predict([test_reviews,test_reviews_char], batch_size=50, verbose=1)[0]\n",
    "        result=np.mean(np.abs(y_pred-test_label),axis=0)\n",
    "        overall=np.round(np.minimum(np.maximum(y_pred,1),5))\n",
    "        print(result,accuracy_score(overall,test_label[:,:1]))\n",
    "        #report the test results according to the best validation results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
